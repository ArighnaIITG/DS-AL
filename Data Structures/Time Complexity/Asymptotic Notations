Asymptotic Notations :

     1. Big-Oh Notation - Gives the rate of growth of running time of an algorithm with respect to 
                          the input given. Gives the worst-case running time, the "upper bound".

                 FORMAL DEFINITION : Let there be some non-negative function g(n).

                                     So, ""O(g(n)) = Set of all functions f(n) such that f(n) <= c*g(n)
                                         for all n>=n0, where c & n0 are constants."" 

                 One example :
                 				f(n) = 5*n**2 + 2*n + 1
                 				g(n) = n**2

                 		So, if c=8, then f(n) <= 8*n**2 for all n >= 1.
                 		So, f(n) has O(n**2) notation.


      2. Omega Notation : Gives the "lower bound" of rate of growth of running time of an algorithm with
      					  respect to the input given.

      			 FORMAL DEFINITION : Let there be some non-negative function g(n).

                                     So, ""omega(g(n)) = Set of all functions f(n) such that c*g(n) <= f(n)
                                         for all n>=n0, where c & n0 are constants."" 

                 One example :
                 				f(n) = 5*n**2 + 2*n + 1
                 				g(n) = n**2

                 		So, if c=5, then 5*g(n) <= f(n) for all n >= 0.
                 		So, f(n) has omega(n**2) notation.


      3. Theta Notation : Gives the "tight bound" of rate of growth of running time of an algorithm with
      					  respect to the input given.

      			 FORMAL DEFINITION : Let there be some non-negative function g(n).

                                     So, ""theta(g(n)) = Set of all functions f(n) such that c1*g(n) <= f(n) <= c2*g(n)
                                         for all n>=n0, where c1, c2 & n0 are constants."" 

                 One example :
                 				f(n) = 5*n**2 + 2*n + 1
                 				g(n) = n**2

                 		So, if c=5, then 5*g(n) <= f(n) <= 8*g(n) for all n >= 0.
                 		So, f(n) has theta(n**2) notation.


       In general, we calcualte time-complexity for 2 cases :

                 1. For very large input sizes
                 2. Worst - case scenario

                 See the general rules of calcualting time complexity in this video :
                 "https://www.youtube.com/watch?v=PFd5s0bHgAQ".

       Some general rules are :

       1. Big-Oh Notation ignores constants.
       2. Certain terms dominate others :

       Eg.  O(1) < O(logn) < O(n) < O(nlogn) < O(n**2) < O(2**n) < O(n!)
